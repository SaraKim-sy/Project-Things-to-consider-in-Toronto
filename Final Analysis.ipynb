{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Insights\n",
    "\n",
    "## Crime Rate and Income Correlation \n",
    "* There's a negative correlation between Average Crime Rate and Average Income\n",
    "* Low Income area has higher crime rate\n",
    "* R value -> negative relationship.\n",
    "* p-value<0.005 -> A statistically significant test result\n",
    "* The stacked bar graph shows Crime Count per neighborhood for each Income Group which depicts lower income regions have higher crime rate per neighborhood.\n",
    "\n",
    "## Red Light Cameras Analysis\n",
    "* From the graphs above, we can see that the majority of red light cameras are implemented in regions with an average income of 50-100K. Comparing this with the total number of speeding tickets per income region we see that the same income region holds the most amount of speeding tickets. We can conclude from this that red light cameras are not necessarly placed in low income regions, but more-so regions where speeding is more commonplace.\n",
    "\n",
    "## House Prices and Crime Rate Correlation\n",
    "* It seems that there is a very weak negative correlation between  crime rate and house prices.\n",
    "\n",
    "## Starbucks Locations Analysis\n",
    "* The Number of Starbucks Stores vs. Average Income scatter plot shows that it seems that there is no correlation between starbucks stores location and income. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Graphs and Analysis/Final_Data2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-3264d9a3f911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Graphs and Analysis/Final_Data2.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    686\u001b[0m     )\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 948\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\geo_env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Graphs and Analysis/Final_Data2.csv'"
     ]
    }
   ],
   "source": [
    "final_df = pd.read_csv('Graphs and Analysis/Final_Data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime and Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the IQR and quantitatively determine if there are any potential outliers in Average Income.\n",
    "\n",
    "# Calculate qualtiles and IQR\n",
    "qualtiles = final_df['Average_Income'].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "first_qualtile = qualtiles[0.25]\n",
    "third_qualtile = qualtiles[0.75]\n",
    "\n",
    "iqr = third_qualtile - first_qualtile\n",
    "\n",
    "# Calculate lower bound and upper bound\n",
    "lower_bound = first_qualtile - (1.5 * iqr)\n",
    "upper_bound = third_qualtile + (1.5 * iqr)\n",
    "\n",
    "# The final dataframe without outliers\n",
    "outliers_removed_df = final_df.loc[(final_df['Average_Income'] <= upper_bound) & (final_df['Average_Income'] >= lower_bound), :]\n",
    "outliers_removed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed outlier\n",
    "sorted_df = outliers_removed_df.sort_values(\"Average_Income\")\n",
    "df = sorted_df.groupby('Income Group')['Total Average Rate'].sum()\n",
    "df.plot(kind='bar', x='Income Group', y='Total Average Rate')\n",
    "plt.title(\"Income Range vs. Total Crime Rate\")\n",
    "plt.xlabel(\"Income Range\")\n",
    "plt.ylabel(\"Total Crime Rate\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creat linear regression plots \n",
    "\n",
    "income = outliers_removed_df[\"Average_Income\"]\n",
    "crime = outliers_removed_df[\"Total Average Rate\"]\n",
    "\n",
    "#plot\n",
    "slope, int, r, p, std_err = st.linregress(income, crime)\n",
    "\n",
    "#Create equation of line\n",
    "eq_line = slope * income + int\n",
    "\n",
    "plt.scatter(income, crime, color= 'red', label = 'actual data')\n",
    "plt.plot(income, eq_line, '--')\n",
    "plt.xlabel(\"Average Income\")\n",
    "plt.ylabel(\"Average Crime Rate\")\n",
    "plt.show()\n",
    "\n",
    "print(r)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime and Income Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort the data on Income\n",
    "sorted_df = final_df.sort_values(\"Average_Income\", ascending = True)\n",
    "\n",
    "#Count Neighborhoods for each Income group and append it to our dataframe\n",
    "count_neighborhood_df = sorted_df.groupby([\"Income Group\"])[\"Neighbourhood\"].count().replace(0,np.nan).dropna().astype(int)\n",
    "\n",
    "#Plot the bar graph showing count of neighborhoods for each Income Range\n",
    "count_neighborhood_df.plot(kind ='bar',color = 'crimson',figsize=(12,7))\n",
    "\n",
    "# Set labels for axes\n",
    "plt.xticks(rotation=90,fontsize = 13)\n",
    "plt.xlabel(\"Income Group\",fontsize = 15)\n",
    "plt.ylabel(\"Neighborhood Count\",fontsize = 15)\n",
    "plt.title(\"Neighborhood Count for each Income Group\",fontsize = 18)\n",
    "\n",
    "#Display resulting plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch sum of each crime type for each Income Range\n",
    "grouped_df =final_df.groupby([\"Income Group\"]).agg(\n",
    "    {\n",
    "         'Assault Rate':sum,    \n",
    "         'Auto Theft Rate': sum,  \n",
    "         'Break&Enter Rate': sum , \n",
    "        'Homicide Rate': sum,\n",
    "        'Robberey Rate': sum,\n",
    "        'Theft Over Rate': sum\n",
    "    }\n",
    ")\n",
    "\n",
    "# Count Neighborhoods for each Income group and append it to our dataframe\n",
    "count_neighborhood_df = final_df.groupby([\"Income Group\"]).count()[\"Neighbourhood\"] \n",
    "grouped_df[\"Count_Neighborhood\"] = count_neighborhood_df\n",
    "\n",
    "#Drop row if it has NaN values for all columns\n",
    "grouped_df=grouped_df.replace(0,np.nan).dropna(thresh=6).fillna(0)\n",
    "\n",
    "#Divide each crime rate with Neighborhood count so as to find values per neighborhood\n",
    "grouped_df[\"Assault Rate\"] = (grouped_df[\"Assault Rate\"])/(grouped_df[\"Count_Neighborhood\"])\n",
    "grouped_df[\"Auto Theft Rate\"] = (grouped_df[\"Auto Theft Rate\"])/(grouped_df[\"Count_Neighborhood\"])\n",
    "grouped_df[\"Break&Enter Rate\"] = (grouped_df[\"Break&Enter Rate\"])/(grouped_df[\"Count_Neighborhood\"])\n",
    "grouped_df[\"Homicide Rate\"] = (grouped_df[\"Homicide Rate\"])/(grouped_df[\"Count_Neighborhood\"])\n",
    "grouped_df[\"Robberey Rate\"] = (grouped_df[\"Robberey Rate\"])/(grouped_df[\"Count_Neighborhood\"])\n",
    "grouped_df[\"Theft Over Rate\"] = (grouped_df[\"Theft Over Rate\"])/(grouped_df[\"Count_Neighborhood\"])\n",
    "\n",
    "#Plot the bar graph showing crime count per neighborhood for each Income Range\n",
    "colors = ['purple','gold','crimson','darkgoldenrod','plum','royalblue']\n",
    "grouped_df.plot(kind ='bar', stacked = True,color = colors,figsize=(12,7))\n",
    "\n",
    "# Set labels for axes\n",
    "plt.xticks(rotation=90,fontsize = 13)\n",
    "plt.xlabel(\"Income Group\",fontsize = 15)\n",
    "plt.ylabel(\"Crime Count per Neighborhood\",fontsize = 15)\n",
    "plt.title(\"Crime Count per Neighborhood for each Income Group\",fontsize = 18)\n",
    "\n",
    "#Display resulting plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Light Cameras Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display income & red lights plot\n",
    "sorted_df = final_df.sort_values(\"Average_Income\")\n",
    "df1 = sorted_df.groupby('Income Group', sort=False)['Number of Red Lights'].sum()\n",
    "df1.plot(kind='bar', x='Income Group', y='Number of Red Lights')\n",
    "plt.title(\"Income Range vs. Total Red Lights\")\n",
    "plt.xlabel(\"Income Range\")\n",
    "plt.ylabel(\"Total Red Lights\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display income & speeding plot\n",
    "df2 = sorted_df.groupby('Income Group', sort = False)['Speeding'].sum()\n",
    "df2.plot(kind='bar', x='Income Group', y='Speeding Count')\n",
    "plt.title(\"Income Range vs. Speeding Count\")\n",
    "plt.xlabel(\"Income Range\")\n",
    "plt.ylabel(\"Total Speeding Counts\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starbucks Locations Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate regression values and creat linear regression plots\n",
    "def linear_regression_plot(x_values, y_values, x_label, y_label, annotate_point):\n",
    "    \n",
    "    mask = ~np.isnan(x_values) & ~np.isnan(y_values)\n",
    "    slope, intercept, r, p, std_err = st.linregress(x_values[mask], y_values[mask])\n",
    "    \n",
    "    # Regression values\n",
    "    regression_values = slope * x_values + intercept\n",
    "    \n",
    "    # Create a equation of line    \n",
    "    eq_line = f\"{round(slope, 2)}x + {round(intercept, 2)}\"\n",
    "\n",
    "    # Create a plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x_values, y_values, color='green', alpha=0.5)\n",
    "    \n",
    "    plt.plot(x_values, regression_values, color='green')\n",
    "    plt.annotate(eq_line, annotate_point, color='green', fontsize=16)\n",
    "    \n",
    "    plt.title(f'{y_label} vs. {x_label}', fontsize=15)\n",
    "    plt.xlabel(f'{x_label}', fontsize=12)\n",
    "    plt.ylabel(f'{y_label}', fontsize=12)\n",
    "               \n",
    "    plt.grid()\n",
    "\n",
    "    # Display the figures\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'The correlation coefficient is {round(r, 5)}.')\n",
    "    print(f'p value is {round(p, 5)}.')\n",
    "    print(f'r square value is {round(r**2, 5)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df variables (did not exclude outliers)\n",
    "\n",
    "final_avg_income = final_df['Average_Income']\n",
    "final_med_income = final_df['Median_Income']\n",
    "final_sb = final_df['Number of Starbucks Stores']\n",
    "final_crime = final_df['Total Average Rate']\n",
    "final_home_prices = final_df['Home Prices']\n",
    "final_population = final_df['Population, 2016']\n",
    "final_red_lights = final_df['Number of Red Lights']\n",
    "final_speeding = final_df['Speeding']\n",
    "\n",
    "starbucks_label = 'Total Number of Starbucks Stores'\n",
    "avg_income_label = 'Average Income'\n",
    "med_income_label = 'Median Income'\n",
    "home_prices_label = 'House Prices'\n",
    "population_label = 'Population'\n",
    "crime_label = 'Total Average Crime Rate'\n",
    "red_lights_label = 'Total Red Lights'\n",
    "speeding_label = 'Total Spedding Counts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df - average income vs. starbucks stores\n",
    "\n",
    "linear_regression_plot(final_avg_income, final_sb, avg_income_label, starbucks_label, (300000, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices and Crime Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_plot(final_home_prices, final_crime, home_prices_label, crime_label, (1000000, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
